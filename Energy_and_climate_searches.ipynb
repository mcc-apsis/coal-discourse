{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/anaconda3/envs/textmining/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "# import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# preamble for jupyter notebook and django\n",
    "import django\n",
    "import platform\n",
    "from django.db.models import Q, F, Sum, Count, FloatField, Case, When\n",
    "\n",
    "if platform.node() == \"mcc-apsis\":\n",
    "    sys.path.append('/home/muef/tmv/BasicBrowser/')\n",
    "else:\n",
    "    # local paths\n",
    "    sys.path.append('/media/Data/MCC/tmv/BasicBrowser/')\n",
    "\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BasicBrowser.settings\")\n",
    "django.setup()\n",
    "\n",
    "# import from appended path\n",
    "import parliament.models as pm\n",
    "from parliament.tasks import do_search, run_tm\n",
    "import cities.models as cmodels\n",
    "from django.contrib.auth.models import User\n",
    "import tmv_app.models as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "docs = pm.Document.objects.filter(parlperiod__n=17, text_source=\"from https://www.bundestag.de/service/opendata \"\n",
    "                                              +\"(scans of pdfs with xml metadata)\" )\n",
    "print(docs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finn\n"
     ]
    }
   ],
   "source": [
    "#user1 = User.objects.create_user('finn', 'mueller-hansen@mcc-berlin.net', 'mcc123')\n",
    "user1, created =  User.objects.get_or_create(username='finn', email='mueller-hansen@mcc-berlin.net')\n",
    "print(user1)\n",
    "user1.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Note: saving of paragraph and utterance count not working properly, only on the second call of do_search!\n",
    "# pm.Search.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of topics\n",
    "K = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119621\n",
      "13126\n",
      "<QuerySet [<RunStats: RunStats object (114)>]>\n"
     ]
    }
   ],
   "source": [
    "# simple search\n",
    "ut_search_tei, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Energie tei utterance\",\n",
    "                text=\"energie\",\n",
    "                creator=user1,\n",
    "                document_source=\"GermaParlTEI\",\n",
    "                search_object_type=2)\n",
    "ut_search_tei.save()\n",
    "if created:\n",
    "    print(\"doing search\")\n",
    "    do_search(ut_search_tei.id)\n",
    "print(ut_search_tei.par_count)\n",
    "print(ut_search_tei.utterance_count)\n",
    "print(ut_search_tei.runstats_set.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating term frequency-inverse document frequency matrix (11.917436838150024)\n",
      "save terms to db (145.8682234287262)\n",
      "running matrix factorization with NMF (382.7127778530121)\n",
      "Reconstruction error of nmf: 105.77107325854838\n",
      "saving document topic matrix to db (507.47930002212524)\n",
      "topic model run done (539.167820930481)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_tei.id, K, method=\"NM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dynamic NMF algorithm\n",
      "\n",
      "#######################\n",
      "in period 13: 984 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 9.106s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.944s.\n",
      "Adding topicterms to db\n",
      "done in 15.460s.\n",
      "\n",
      "#######################\n",
      "in period 14: 1974 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 23.690s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 10.230s.\n",
      "Adding topicterms to db\n",
      "done in 33.591s.\n",
      "\n",
      "#######################\n",
      "in period 15: 1141 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 16.282s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 7.951s.\n",
      "Adding topicterms to db\n",
      "done in 24.361s.\n",
      "\n",
      "#######################\n",
      "in period 16: 2807 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 29.555s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 18.535s.\n",
      "Adding topicterms to db\n",
      "done in 41.779s.\n",
      "\n",
      "#######################\n",
      "in period 17: 3747 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 35.671s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 14.222s.\n",
      "Adding topicterms to db\n",
      "done in 33.049s.\n",
      "\n",
      "#######################\n",
      "in period 18: 2473 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 19.627s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 7.723s.\n",
      "Adding topicterms to db\n",
      "done in 20.783s.\n",
      "<QuerySet [<Topic: Topic 2>, <Topic: Topic 3>, <Topic: Topic 4>, <Topic: Topic 5>, <Topic: Topic 8>, <Topic: Topic 9>, <Topic: Topic 10>, <Topic: Topic 12>, <Topic: Topic 13>, <Topic: Topic 14>, <Topic: Topic 15>, <Topic: Topic 16>, <Topic: Topic 18>, <Topic: Topic 19>, <Topic: Topic 20>, <Topic: Topic 21>, <Topic: Topic 23>, <Topic: Topic 24>, <Topic: Topic 25>, <Topic: Topic 26>, '...(remaining elements truncated)...']>\n",
      "[421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450]\n",
      "Adding topicterms to db\n",
      "done in 0.886s.\n",
      "saving primary topic not working\n",
      "114\n",
      "RunStats object (114)\n",
      "done! total time: 13 minutes and 12 seconds\n",
      "a maximum of 704.412 MB was used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_tei.id, K, method=\"DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115778\n",
      "12616\n",
      "<QuerySet [<RunStats: RunStats object (23)>]>\n"
     ]
    }
   ],
   "source": [
    "# simple search\n",
    "ut_search_pdf, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Energie pdf utterance\",\n",
    "                text=\"energie\",\n",
    "                creator=user1,\n",
    "                start_date=datetime.date(1996,2,8),\n",
    "                stop_date=datetime.date(2016,12,16),\n",
    "                document_source=\"from https.*scans of pdfs with xml metadata\",\n",
    "                search_object_type=2)\n",
    "ut_search_pdf.save()\n",
    "#do_search(ut_search_pdf.id)\n",
    "print(ut_search_pdf.par_count)\n",
    "print(ut_search_pdf.utterance_count)\n",
    "print(ut_search_pdf.runstats_set.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating term frequency-inverse document frequency matrix (0.0049839019775390625)\n",
      "save terms to db (120.81183576583862)\n",
      "running matrix factorization with NMF (294.0275774002075)\n",
      "Reconstruction error of nmf: 104.06570117608332\n",
      "saving document topic matrix to db (401.5354177951813)\n",
      "topic model run done (422.249712228775)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76017\n",
      "8158\n",
      "<QuerySet [<RunStats: RunStats object (45)>]>\n"
     ]
    }
   ],
   "source": [
    "# simple search\n",
    "ut_search_tei, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Klima tei utterance\",\n",
    "                text=\"klima\",\n",
    "                creator=user1,\n",
    "                document_source=\"GermaParlTEI\",\n",
    "                search_object_type=2)\n",
    "ut_search_tei.save()\n",
    "if created:\n",
    "    print(\"doing search\")\n",
    "print(ut_search_tei.par_count)\n",
    "print(ut_search_tei.utterance_count)\n",
    "print(ut_search_tei.runstats_set.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dynamic NMF algorithm\n",
      "\n",
      "#######################\n",
      "in period 13: 522 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.700s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.374s.\n",
      "Adding topicterms to db\n",
      "done in 12.359s.\n",
      "\n",
      "#######################\n",
      "in period 14: 1031 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 11.048s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 4.757s.\n",
      "Adding topicterms to db\n",
      "done in 16.955s.\n",
      "\n",
      "#######################\n",
      "in period 15: 673 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 6.933s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.826s.\n",
      "Adding topicterms to db\n",
      "done in 11.941s.\n",
      "\n",
      "#######################\n",
      "in period 16: 2025 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 17.752s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 7.233s.\n",
      "Adding topicterms to db\n",
      "done in 23.139s.\n",
      "\n",
      "#######################\n",
      "in period 17: 2263 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 17.939s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 8.278s.\n",
      "Adding topicterms to db\n",
      "done in 22.803s.\n",
      "\n",
      "#######################\n",
      "in period 18: 1644 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 14.096s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 5.357s.\n",
      "Adding topicterms to db\n",
      "done in 18.153s.\n",
      "<QuerySet [<Topic: Topic 30>, <Topic: Topic 29>, <Topic: Topic 28>, <Topic: Topic 27>, <Topic: Topic 26>, <Topic: Topic 25>, <Topic: Topic 24>, <Topic: Topic 23>, <Topic: Topic 22>, <Topic: Topic 21>, <Topic: Topic 20>, <Topic: Topic 19>, <Topic: Topic 18>, <Topic: Topic 17>, <Topic: Topic 16>, <Topic: Topic 15>, <Topic: Topic 14>, <Topic: Topic 13>, <Topic: Topic 12>, <Topic: Topic 11>, '...(remaining elements truncated)...']>\n",
      "[451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480]\n",
      "Adding topicterms to db\n",
      "done in 0.797s.\n",
      "115\n",
      "RunStats object (115)\n",
      "done! total time: 9 minutes and 16 seconds\n",
      "a maximum of 785.812 MB was used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_tei.id, K, method='DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7860 utterances with search klima\n",
      "73983\n",
      "7860\n",
      "73983\n",
      "7860\n",
      "<QuerySet [<RunStats: RunStats object (25)>]>\n"
     ]
    }
   ],
   "source": [
    "# simple search\n",
    "ut_search_pdf, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Klima pdf utterance\",\n",
    "                text=\"klima\",\n",
    "                creator=user1,\n",
    "                start_date=datetime.date(1996,2,8),\n",
    "                stop_date=datetime.date(2016,12,16),\n",
    "                document_source=\"from https.*scans of pdfs with xml metadata\",\n",
    "                search_object_type=2)\n",
    "ut_search_pdf.save()\n",
    "do_search(ut_search_pdf.id)\n",
    "print(ut_search_pdf.par_count)\n",
    "print(ut_search_pdf.utterance_count)\n",
    "print(ut_search_pdf.runstats_set.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating term frequency-inverse document frequency matrix (0.014417886734008789)\n",
      "save terms to db (88.59375190734863)\n",
      "running matrix factorization with NMF (270.44180965423584)\n",
      "Reconstruction error of nmf: 82.13760848425743\n",
      "saving document topic matrix to db (351.04408836364746)\n",
      "topic model run done (365.4467327594757)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

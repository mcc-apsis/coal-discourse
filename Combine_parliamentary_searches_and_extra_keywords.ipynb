{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/anaconda3/envs/textmining/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "# preamble for jupyter notebook and django\n",
    "import django\n",
    "import platform\n",
    "\n",
    "if platform.node() == \"srv-mcc-apsis\":\n",
    "    sys.path.append(\"/home/muef/tmv/BasicBrowser/\")\n",
    "    #sys.path.append('/home/leey/tmv/BasicBrowser/')\n",
    "else:\n",
    "    # local paths\n",
    "    sys.path.append('/media/Data/MCC/tmv/BasicBrowser/')\n",
    "\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BasicBrowser.settings\")\n",
    "django.setup()\n",
    "\n",
    "# import from appended path\n",
    "import parliament.models as pm\n",
    "from parliament.tasks import do_search, run_tm, combine_searches\n",
    "import cities.models as cmodels\n",
    "from django.contrib.auth.models import User\n",
    "from tmv_app.models import *\n",
    "from utils.tm_mgmt import update_topic_scores\n",
    "from django.db.models import Q, Count, Func, F, Sum, Avg, Value as V\n",
    "from django.db.models.functions import TruncDate, TruncMonth, TruncYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1, created =  User.objects.get_or_create(username='muef')\n",
    "user1.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32956\n",
      "2967\n",
      "<QuerySet [<RunStats: RunStats object (136)>, <RunStats: RunStats object (135)>]>\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# simple search for utterances\n",
    "par_search, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Kohle tei utterance\",\n",
    "                text='(?<!Europ채ische Gemeinschaft f체r )kohle(?!nwasser)(?!nstoff)(?!ndiox)(?!nmonox)(?!rnte)',\n",
    "                creator=user1,\n",
    "                document_source=\"GermaParlTEI\",\n",
    "                search_object_type=2)\n",
    "par_search.save()\n",
    "\n",
    "if created:\n",
    "    print(\"doing search\")\n",
    "    do_search(par_search.id)\n",
    "print(par_search.par_count)\n",
    "print(par_search.utterance_count)\n",
    "print(par_search.runstats_set.all())\n",
    "print(par_search.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "24\n",
      "<QuerySet []>\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "# simple search for utterances\n",
    "par_search2, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Kohle pdf utterance 18/211 - 18/245\",\n",
    "                text='(?<!Europ채ische Gemeinschaft f체r )kohle(?!nwasser)(?!nstoff)(?!ndiox)(?!nmonox)(?!rnte)',\n",
    "                creator=user1,\n",
    "                start_date=date(2017,1,18),\n",
    "                stop_date=date(2017,5,9),\n",
    "                document_source=\"from https.*scans of pdfs with xml metadata\",\n",
    "                search_object_type=2)\n",
    "par_search2.save()\n",
    "\n",
    "if created:\n",
    "    print(\"doing search\")\n",
    "    do_search(par_search2.id)\n",
    "print(par_search2.par_count)\n",
    "print(par_search2.utterance_count)\n",
    "print(par_search2.runstats_set.all())\n",
    "print(par_search2.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add search for current parliament here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2,)}\n",
      "all search object types identical\n",
      "2\n",
      "Created combined search: id = 67\n"
     ]
    }
   ],
   "source": [
    "# test combine function\n",
    "\n",
    "combine_searches([par_search.id,par_search2.id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2991\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "s = pm.Search.objects.get(id=65)\n",
    "print(pm.Utterance.objects.filter(search_matches=s).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting topic model with method = lda, K = 30, language = german, max_df = 0.95, min_df = 5, alpha = 0.01\n",
      "extra stopwords: {'schriftlich', 'dam', 'mensch', 'herrn', 'federfuhr', 'drucksach', 'tagesordn', 'geht', 'besond', 'bitt', 'beschlussempfehl', 'vorlag', 'berat', 'kollegin', 'beantwortet', 'verordn', 'notwend', 'gesagt', 'heut', 'abgeordnet', 'neu', 'gibt', 'handzeich', 'mehr', 'regel', 'lieb', 'tagesordnungspunkt', 'antwort', 'moglich', 'sag', 'vervielfaltigt', 'berichterstatt', 'beantwort', 'rat', 'parlamentar', 'welt', 'mocht', 'erst', 'beschlussfass', 'bereit', 'bericht', 'uberweisungsvorschlag', 'ganz', 'land', 'kind', 'jung', 'anfrag', 'ziff', 'betreff', 'schon', 'ruf', 'antrag', 'aufgab', 'eingebracht', 'zuzustimm', 'wer', 'stimmt', 'glaub', 'uberweis', 'frag', 'schreib', 'verehrt', 'herr', 'enthalt', 'uberwies', 'kolleg', 'brauch', 'altestenrat', 'polit', 'jahr', 'vorschrift', 'gegenprob', 'word', 'frau', 'prasidentin', 'massnahm', 'abstimm', 'bundnis', 'ausschuss', 'fraktion', 'ander', 'wunscht', 'angenomm', 'dafur', 'umdruck'}\n",
      "creating term frequency matrix (2.2106714248657227)\n",
      "save terms to db (28.159939527511597)\n",
      "running Latent Dirichlet Allocation (111.10847616195679)\n",
      "saving document topic matrix to db (181.84957814216614)\n",
      "topic model run done (191.34126377105713)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords from overlap analysis\n",
    "extra_stopwords = set([\"herr\", \"jahr\", \"mehr\", \"sag\", \"land\", \"schon\", \"neu\", \"ganz\", \"polit\",\n",
    "                   \"heut\", \"antrag\", \"gibt\", \"kolleg\", \"geht\", \"berat\", \"frag\", \"mensch\"])\n",
    "\n",
    "# stopwords from overlap analysis + irrelevant topics\n",
    "extra_stopwords = set(['stimmt', 'ganz', 'schreib', 'drucksach', 'kolleg', 'gesagt', 'notwend', 'aufgab', 'parlamentar', 'rat', 'heut', 'bitt', 'tagesordnungspunkt', 'wunscht',\n",
    "                       'neu', 'abstimm', 'zuzustimm', 'mensch', 'abgeordnet', 'vorschrift', 'ziff', 'beantwort', 'land', 'altestenrat', 'ausschuss', 'federfuhr', 'berichterstatt',\n",
    "                       'beschlussempfehl', 'fraktion', 'bundnis', 'moglich', 'schriftlich', 'ander', 'handzeich',\n",
    "                       'uberweisungsvorschlag', 'uberweis', 'welt', 'wer', 'regel', 'geht', 'verehrt', 'jahr', 'enthalt',\n",
    "                       'polit', 'kind', 'mocht', 'vervielfaltigt', 'verordn', 'massnahm', 'antwort', 'prasidentin', 'vorlag',\n",
    "                       'erst', 'tagesordn', 'sag', 'herrn', 'anfrag', 'gibt', 'besond', 'lieb', 'schon', 'umdruck', 'gegenprob',\n",
    "                       'angenomm', 'kollegin', 'antrag', 'bereit', 'berat', 'frau', 'jung', 'betreff', 'brauch', 'dafur', 'word',\n",
    "                       'eingebracht', 'ruf', 'uberwies', 'frag', 'beschlussfass', 'bericht', 'glaub', 'dam', 'mehr', 'beantwortet',\n",
    "                       'herr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    }
   ],
   "source": [
    "# this probably needs updating for max's new method to submit tasks\n",
    "K_list = [35, 60]\n",
    "\n",
    "for K in K_list:\n",
    "    # run_tm.delay(par_search_pdf_all.id, K=K, method='BT')\n",
    "    # instead of using delay (which sends to the default queue), we use the more \n",
    "    # verbose way to call the funtion (apply async) where we can specify that we\n",
    "    # want to send it to the long queue, which only has two workers\n",
    "    run_tm.apply_async(\n",
    "        args=[par_search_pdf_all.id],\n",
    "        kwargs={\n",
    "            \"K\": K,\n",
    "            \"method\": \"BT\"\n",
    "        },\n",
    "        queue=\"long\"\n",
    "    )\n",
    "    # We don't need to sleep anymore, because we know they are being nicely scheduled\n",
    "    #time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

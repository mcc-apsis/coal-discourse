{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "# import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# preamble for jupyter notebook and django\n",
    "import django\n",
    "import platform\n",
    "from django.db.models import Q, F, Sum, Count, FloatField, Case, When\n",
    "\n",
    "if platform.node() == \"mcc-apsis\":\n",
    "    sys.path.append('/home/muef/tmv/BasicBrowser/')\n",
    "else:\n",
    "    # local paths\n",
    "    sys.path.append('/media/Data/MCC/tmv/BasicBrowser/')\n",
    "\n",
    "sys.path.append('/home/galm/software/django/tmv/BasicBrowser/')\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BasicBrowser.settings\")\n",
    "django.setup()\n",
    "\n",
    "# import from appended path\n",
    "import parliament.models as pm\n",
    "from parliament.tasks import do_search, run_tm\n",
    "import cities.models as cmodels\n",
    "from django.contrib.auth.models import User\n",
    "import tmv_app.models as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "docs = pm.Document.objects.filter(parlperiod__n=17, text_source=\"from https://www.bundestag.de/service/opendata \"\n",
    "                                              +\"(scans of pdfs with xml metadata)\" )\n",
    "print(docs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finn\n"
     ]
    }
   ],
   "source": [
    "#user1 = User.objects.create_user('finn', 'mueller-hansen@mcc-berlin.net', 'mcc123')\n",
    "user1, created =  User.objects.get_or_create(username='finn', email='mueller-hansen@mcc-berlin.net')\n",
    "print(user1)\n",
    "user1.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: saving of paragraph and utterance count not working properly, only on the second call of do_search!\n",
    "# pm.Search.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of topics\n",
    "K = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35298\n",
      "3284\n",
      "<QuerySet [<RunStats: RunStats object (69)>, <RunStats: RunStats object (43)>, <RunStats: RunStats object (97)>, <RunStats: RunStats object (47)>, <RunStats: RunStats object (95)>]>\n"
     ]
    }
   ],
   "source": [
    "# simple search\n",
    "ut_search_tei, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Kohle tei utterance\",\n",
    "                text=\"kohle\",\n",
    "                creator=user1,\n",
    "                document_source=\"GermaParlTEI\",\n",
    "                search_object_type=2)\n",
    "ut_search_tei.save()\n",
    "if created:\n",
    "    do_search(ut_search_tei.id)\n",
    "print(ut_search_tei.par_count)\n",
    "print(ut_search_tei.utterance_count)\n",
    "print(ut_search_tei.runstats_set.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating term frequency-inverse document frequency matrix (2.5341479778289795)\n",
      "save terms to db (33.012356996536255)\n",
      "running matrix factorization with NMF (102.54102802276611)\n",
      "Reconstruction error of nmf: 52.49054515665733\n",
      "saving document topic matrix to db (133.33662724494934)\n",
      "topic model run done (138.63229155540466)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default method is NMF\n",
    "run_tm(ut_search_tei.id, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dynamic NMF algorithm\n",
      "\n",
      "#######################\n",
      "in period 13: 427 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.448s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 4.124s.\n",
      "Adding topicterms to db\n",
      "done in 14.899s.\n",
      "\n",
      "#######################\n",
      "in period 14: 507 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.370s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 5.374s.\n",
      "Adding topicterms to db\n",
      "done in 16.562s.\n",
      "\n",
      "#######################\n",
      "in period 15: 405 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.357s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.771s.\n",
      "Adding topicterms to db\n",
      "done in 14.736s.\n",
      "\n",
      "#######################\n",
      "in period 16: 707 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 7.640s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 8.828s.\n",
      "Adding topicterms to db\n",
      "done in 23.084s.\n",
      "\n",
      "#######################\n",
      "in period 17: 651 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 7.264s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 7.494s.\n",
      "Adding topicterms to db\n",
      "done in 24.507s.\n",
      "\n",
      "#######################\n",
      "in period 18: 587 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.543s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 6.090s.\n",
      "Adding topicterms to db\n",
      "done in 17.467s.\n",
      "<QuerySet [<Topic: Topic 2>, <Topic: Topic 3>, <Topic: Topic 4>, <Topic: Topic 5>, <Topic: Topic 8>, <Topic: Topic 9>, <Topic: Topic 10>, <Topic: Topic 45>, <Topic: Topic 46>, <Topic: Topic 47>, <Topic: Topic 48>, <Topic: Topic 49>, <Topic: Topic 13>, <Topic: Topic 14>, <Topic: Topic 15>, <Topic: Topic 16>, <Topic: Topic 1>, <Topic: Topic 3>, <Topic: Topic 7>, <Topic: Topic 13>, '...(remaining elements truncated)...']>\n",
      "[560, 559, 558, 557, 556, 555, 554, 553, 552, 551, 550, 549, 548, 547, 546, 545, 544, 543, 542, 541, 540, 539, 538, 537, 536, 535, 534, 533, 532, 531, 530, 529, 528, 527, 526, 525, 524, 523, 522, 521, 520, 519, 518, 517, 516, 515, 514, 513, 512, 511]\n",
      "Adding topicterms to db\n",
      "done in 1.167s.\n",
      "123\n",
      "RunStats object (123)\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n",
      "No DocTopics found\n"
     ]
    },
    {
     "ename": "DataError",
     "evalue": "division by zero\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/backends/utils.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, sql, params, *ignored_wrapper_args)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataError\u001b[0m: division by zero\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-87b393be5877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_tm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mut_search_tei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/celery/local.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *a, **kw)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_current_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/celery/app/task.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/MCC/tmv/BasicBrowser/parliament/tasks.py\u001b[0m in \u001b[0;36mrun_tm\u001b[0;34m(s_id, K, language, verbosity, method, max_features, max_df, min_df, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'DT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dnmf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running dynamic NMF algorithm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mrun_dynamic_nmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'BT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BleiDTM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/MCC/tmv/BasicBrowser/utils/run_dtm_parliament.py\u001b[0m in \u001b[0;36mrun_dynamic_nmf\u001b[0;34m(s_id, K, language, verbosity, max_features, max_df, min_df)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mmanagement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update_run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruction_err_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/core/management/__init__.py\u001b[0m in \u001b[0;36mcall_command\u001b[0;34m(command_name, *args, **options)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skip_checks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/core/management/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_migrations_checks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_migrations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_transaction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/MCC/tmv/BasicBrowser/tmv_app/management/commands/update_run.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, *args, **options)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m#management.call_command('corr_topics',run_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m#update_ipcc_coverage(run_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mnormalise_tdts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"BD\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/celery/__init__.py\u001b[0m in \u001b[0;36mnormalise_tdts\u001b[0;34m(run_id)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         tptdts.update(\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mpgrowthn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pgrowth'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/models/query.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCURSOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/models/sql/compiler.py\u001b[0m in \u001b[0;36mexecute_sql\u001b[0;34m(self, result_type)\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0mrelated\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \"\"\"\n\u001b[0;32m-> 1377\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcursor\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/models/sql/compiler.py\u001b[0m in \u001b[0;36mexecute_sql\u001b[0;34m(self, result_type, chunked_fetch, chunk_size)\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0;31m# Might fail for server-side cursors (e.g. connection closed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/backends/utils.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/backends/utils.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_with_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmany\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecutemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/backends/utils.py\u001b[0m in \u001b[0;36m_execute_with_wrappers\u001b[0;34m(self, sql, params, many, executor)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_wrappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmany\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mignored_wrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/backends/utils.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, sql, params, *ignored_wrapper_args)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_executemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mignored_wrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/utils.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdj_exc_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDataError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegrityError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mdj_exc_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/textmining/lib/python3.7/site-packages/django/db/backends/utils.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, sql, params, *ignored_wrapper_args)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_executemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mignored_wrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataError\u001b[0m: division by zero\n"
     ]
    }
   ],
   "source": [
    "run_tm(ut_search_tei.id, 50, method='DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108750\n",
      "8594\n",
      "<QuerySet [<RunStats: RunStats object (121)>, <RunStats: RunStats object (117)>, <RunStats: RunStats object (116)>, <RunStats: RunStats object (119)>, <RunStats: RunStats object (120)>]>\n"
     ]
    }
   ],
   "source": [
    "# simple search\n",
    "ut_search_pdf, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Kohle pdf utterance all\",\n",
    "                text=\"kohle\",\n",
    "                creator=user1,\n",
    "#                start_date=datetime.date(1996,2,8),\n",
    "#                stop_date=datetime.date(2016,12,16),\n",
    "                document_source=\"from https.*scans of pdfs with xml metadata\",\n",
    "                search_object_type=2)\n",
    "ut_search_pdf.save()\n",
    "if created:\n",
    "    do_search(ut_search_pdf.id)\n",
    "print(ut_search_pdf.par_count)\n",
    "print(ut_search_pdf.utterance_count)\n",
    "print(ut_search_pdf.runstats_set.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating term frequency-inverse document frequency matrix (7.246098756790161)\n",
      "save terms to db (140.9236991405487)\n",
      "running matrix factorization with NMF (319.11061358451843)\n",
      "Reconstruction error of nmf: 85.31024041679362\n",
      "saving document topic matrix to db (412.3995473384857)\n",
      "topic model run done (425.2567837238312)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dynamic NMF algorithm\n",
      "\n",
      "#######################\n",
      "in period 1: 620 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 11.540s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.436s.\n",
      "Adding topicterms to db\n",
      "done in 14.120s.\n",
      "\n",
      "#######################\n",
      "in period 2: 315 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 9.854s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.769s.\n",
      "Adding topicterms to db\n",
      "done in 12.812s.\n",
      "\n",
      "#######################\n",
      "in period 3: 265 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.832s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.809s.\n",
      "Adding topicterms to db\n",
      "done in 8.761s.\n",
      "\n",
      "#######################\n",
      "in period 4: 213 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.955s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.602s.\n",
      "Adding topicterms to db\n",
      "done in 8.266s.\n",
      "\n",
      "#######################\n",
      "in period 5: 404 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 11.780s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.629s.\n",
      "Adding topicterms to db\n",
      "done in 13.936s.\n",
      "\n",
      "#######################\n",
      "in period 6: 146 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.043s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.254s.\n",
      "Adding topicterms to db\n",
      "done in 6.814s.\n",
      "\n",
      "#######################\n",
      "in period 7: 308 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 8.722s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.644s.\n",
      "Adding topicterms to db\n",
      "done in 11.273s.\n",
      "\n",
      "#######################\n",
      "in period 8: 473 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 12.456s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 4.342s.\n",
      "Adding topicterms to db\n",
      "done in 16.528s.\n",
      "\n",
      "#######################\n",
      "in period 9: 261 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.886s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.781s.\n",
      "Adding topicterms to db\n",
      "done in 8.637s.\n",
      "\n",
      "#######################\n",
      "in period 10: 693 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 8.785s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.883s.\n",
      "Adding topicterms to db\n",
      "done in 14.969s.\n",
      "\n",
      "#######################\n",
      "in period 11: 828 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 11.671s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 4.035s.\n",
      "Adding topicterms to db\n",
      "done in 15.714s.\n",
      "\n",
      "#######################\n",
      "in period 12: 637 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 8.652s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.286s.\n",
      "Adding topicterms to db\n",
      "done in 13.818s.\n",
      "\n",
      "#######################\n",
      "in period 13: 616 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 8.274s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.296s.\n",
      "Adding topicterms to db\n",
      "done in 13.243s.\n",
      "\n",
      "#######################\n",
      "in period 14: 484 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.647s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.238s.\n",
      "Adding topicterms to db\n",
      "done in 10.280s.\n",
      "\n",
      "#######################\n",
      "in period 15: 395 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.777s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.874s.\n",
      "Adding topicterms to db\n",
      "done in 10.278s.\n",
      "\n",
      "#######################\n",
      "in period 16: 658 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 6.714s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.560s.\n",
      "Adding topicterms to db\n",
      "done in 11.169s.\n",
      "\n",
      "#######################\n",
      "in period 17: 634 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.954s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.560s.\n",
      "Adding topicterms to db\n",
      "done in 10.580s.\n",
      "\n",
      "#######################\n",
      "in period 18: 644 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.590s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.190s.\n",
      "Adding topicterms to db\n",
      "done in 9.438s.\n",
      "<QuerySet [<Topic: Topic 7>, <Topic: Topic 8>, <Topic: Topic 10>, <Topic: Topic 11>, <Topic: Topic 12>, <Topic: Topic 14>, <Topic: Topic 15>, <Topic: Topic 16>, <Topic: Topic 17>, <Topic: Topic 18>, <Topic: Topic 19>, <Topic: Topic 20>, <Topic: Topic 2>, <Topic: Topic 3>, <Topic: Topic 4>, <Topic: Topic 6>, <Topic: Topic 7>, <Topic: Topic 9>, <Topic: Topic 10>, <Topic: Topic 11>, '...(remaining elements truncated)...']>\n",
      "[481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510]\n",
      "Adding topicterms to db\n",
      "done in 1.024s.\n",
      "saving primary topic not working\n",
      "117\n",
      "RunStats object (117)\n",
      "done! total time: 24 minutes and 55 seconds\n",
      "a maximum of 1220.048 MB was used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, K, method='DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Blei DTM algorithm\n",
      "Extracting word features...\n",
      "done in 119.577s.\n",
      "Save terms to DB\n",
      "write input files for Blei algorithm\n",
      "Calling Blei algorithm\n",
      "Blei algorithm done\n",
      "upload dtm results to db\n",
      "writing topic terms\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "writing doctopics\n",
      "119\n",
      "RunStats object (119)\n",
      "done! total time: 268 minutes and 34 seconds\n",
      "a maximum of 945.744 MB was used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, 30, method='BT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Blei DTM algorithm\n",
      "Extracting word features...\n",
      "done in 124.474s.\n",
      "Save terms to DB\n",
      "write input files for Blei algorithm\n",
      "Calling Blei algorithm\n",
      "Blei algorithm done\n",
      "upload dtm results to db\n",
      "writing topic terms\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "13\n",
      "7\n",
      "15\n",
      "3\n",
      "5\n",
      "9\n",
      "11\n",
      "1\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "17\n",
      "19\n",
      "25\n",
      "21\n",
      "23\n",
      "27\n",
      "29\n",
      "32\n",
      "34\n",
      "31\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "33\n",
      "46\n",
      "39\n",
      "37\n",
      "41\n",
      "35\n",
      "43\n",
      "45\n",
      "48\n",
      "47\n",
      "49\n",
      "writing doctopics\n",
      "122\n",
      "RunStats object (122)\n",
      "done! total time: 410 minutes and 33 seconds\n",
      "a maximum of 778.852 MB was used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, 50, method='BT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

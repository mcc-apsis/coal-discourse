{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "# import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# preamble for jupyter notebook and django\n",
    "import django\n",
    "import platform\n",
    "from django.db.models import Q, F, Sum, Count, FloatField, Case, When\n",
    "\n",
    "if platform.node() == \"mcc-apsis\":\n",
    "    sys.path.append('/home/muef/tmv/BasicBrowser/')\n",
    "else:\n",
    "    # local paths\n",
    "    sys.path.append('/media/Data/MCC/tmv/BasicBrowser/')\n",
    "\n",
    "#sys.path.append('/home/galm/software/django/tmv/BasicBrowser/')\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BasicBrowser.settings\")\n",
    "django.setup()\n",
    "\n",
    "# import from appended path\n",
    "import parliament.models as pm\n",
    "from parliament.tasks import do_search, run_tm\n",
    "import cities.models as cmodels\n",
    "from django.contrib.auth.models import User\n",
    "import tmv_app.models as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "docs = pm.Document.objects.filter(parlperiod__n=17, text_source=\"from https://www.bundestag.de/service/opendata \"\n",
    "                                              +\"(scans of pdfs with xml metadata)\" )\n",
    "print(docs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muef\n"
     ]
    }
   ],
   "source": [
    "#user1 = User.objects.create_user('finn', 'mueller-hansen@mcc-berlin.net', 'mcc123')\n",
    "user1, created =  User.objects.get_or_create(username='muef', email='mueller-hansen@mcc-berlin.net')\n",
    "print(user1)\n",
    "user1.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Note: saving of paragraph and utterance count not working properly, only on the second call of do_search!\n",
    "# pm.Search.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of topics\n",
    "K = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 utterances with search CCS\n",
      "1598\n",
      "230\n",
      "None\n",
      "None\n",
      "<QuerySet []>\n"
     ]
    }
   ],
   "source": [
    "# simple search\n",
    "ut_search_tei, created = pm.Search.objects.get_or_create(\n",
    "                title=\"CCS tei utterance\",\n",
    "                text=\"CCS\",\n",
    "                creator=user1,\n",
    "                document_source=\"GermaParlTEI\",\n",
    "                search_object_type=2)\n",
    "ut_search_tei.save()\n",
    "if created:\n",
    "    do_search(ut_search_tei.id)\n",
    "print(ut_search_tei.par_count)\n",
    "print(ut_search_tei.utterance_count)\n",
    "print(ut_search_tei.runstats_set.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating term frequency-inverse document frequency matrix (0.3456270694732666)\n",
      "save terms to db (3.595463275909424)\n",
      "running matrix factorization with NMF (9.726431369781494)\n",
      "Reconstruction error of nmf: 12.395549969658344\n",
      "saving document topic matrix to db (15.993393659591675)\n",
      "topic model run done (17.409051656723022)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default method is NMF\n",
    "run_tm(ut_search_tei.id, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Blei DTM algorithm\n",
      "Extracting word features...\n",
      "done in 3.220s.\n",
      "Save terms to DB\n"
     ]
    }
   ],
   "source": [
    "run_tm(ut_search_tei.id, 30, method='BT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108750\n",
      "8594\n",
      "<QuerySet [<RunStats: RunStats object (121)>, <RunStats: RunStats object (117)>, <RunStats: RunStats object (116)>, <RunStats: RunStats object (119)>, <RunStats: RunStats object (120)>]>\n"
     ]
    }
   ],
   "source": [
    "# simple search\n",
    "ut_search_pdf, created = pm.Search.objects.get_or_create(\n",
    "                title=\"Kohle pdf utterance all\",\n",
    "                text=\"kohle\",\n",
    "                creator=user1,\n",
    "#                start_date=datetime.date(1996,2,8),\n",
    "#                stop_date=datetime.date(2016,12,16),\n",
    "                document_source=\"from https.*scans of pdfs with xml metadata\",\n",
    "                search_object_type=2)\n",
    "ut_search_pdf.save()\n",
    "if created:\n",
    "    do_search(ut_search_pdf.id)\n",
    "print(ut_search_pdf.par_count)\n",
    "print(ut_search_pdf.utterance_count)\n",
    "print(ut_search_pdf.runstats_set.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating term frequency-inverse document frequency matrix (7.246098756790161)\n",
      "save terms to db (140.9236991405487)\n",
      "running matrix factorization with NMF (319.11061358451843)\n",
      "Reconstruction error of nmf: 85.31024041679362\n",
      "saving document topic matrix to db (412.3995473384857)\n",
      "topic model run done (425.2567837238312)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dynamic NMF algorithm\n",
      "\n",
      "#######################\n",
      "in period 1: 620 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 11.540s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.436s.\n",
      "Adding topicterms to db\n",
      "done in 14.120s.\n",
      "\n",
      "#######################\n",
      "in period 2: 315 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 9.854s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.769s.\n",
      "Adding topicterms to db\n",
      "done in 12.812s.\n",
      "\n",
      "#######################\n",
      "in period 3: 265 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.832s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.809s.\n",
      "Adding topicterms to db\n",
      "done in 8.761s.\n",
      "\n",
      "#######################\n",
      "in period 4: 213 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.955s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.602s.\n",
      "Adding topicterms to db\n",
      "done in 8.266s.\n",
      "\n",
      "#######################\n",
      "in period 5: 404 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 11.780s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.629s.\n",
      "Adding topicterms to db\n",
      "done in 13.936s.\n",
      "\n",
      "#######################\n",
      "in period 6: 146 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.043s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.254s.\n",
      "Adding topicterms to db\n",
      "done in 6.814s.\n",
      "\n",
      "#######################\n",
      "in period 7: 308 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 8.722s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.644s.\n",
      "Adding topicterms to db\n",
      "done in 11.273s.\n",
      "\n",
      "#######################\n",
      "in period 8: 473 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 12.456s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 4.342s.\n",
      "Adding topicterms to db\n",
      "done in 16.528s.\n",
      "\n",
      "#######################\n",
      "in period 9: 261 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.886s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.781s.\n",
      "Adding topicterms to db\n",
      "done in 8.637s.\n",
      "\n",
      "#######################\n",
      "in period 10: 693 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 8.785s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.883s.\n",
      "Adding topicterms to db\n",
      "done in 14.969s.\n",
      "\n",
      "#######################\n",
      "in period 11: 828 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 11.671s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 4.035s.\n",
      "Adding topicterms to db\n",
      "done in 15.714s.\n",
      "\n",
      "#######################\n",
      "in period 12: 637 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 8.652s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.286s.\n",
      "Adding topicterms to db\n",
      "done in 13.818s.\n",
      "\n",
      "#######################\n",
      "in period 13: 616 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 8.274s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 3.296s.\n",
      "Adding topicterms to db\n",
      "done in 13.243s.\n",
      "\n",
      "#######################\n",
      "in period 14: 484 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.647s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.238s.\n",
      "Adding topicterms to db\n",
      "done in 10.280s.\n",
      "\n",
      "#######################\n",
      "in period 15: 395 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 4.777s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 1.874s.\n",
      "Adding topicterms to db\n",
      "done in 10.278s.\n",
      "\n",
      "#######################\n",
      "in period 16: 658 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 6.714s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.560s.\n",
      "Adding topicterms to db\n",
      "done in 11.169s.\n",
      "\n",
      "#######################\n",
      "in period 17: 634 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.954s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.560s.\n",
      "Adding topicterms to db\n",
      "done in 10.580s.\n",
      "\n",
      "#######################\n",
      "in period 18: 644 docs\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 5.590s.\n",
      "Save terms to DB\n",
      "Fitting the NMF model with tf-idf features, n_samples=1000 and max_features=20000...\n",
      "done in 2.190s.\n",
      "Adding topicterms to db\n",
      "done in 9.438s.\n",
      "<QuerySet [<Topic: Topic 7>, <Topic: Topic 8>, <Topic: Topic 10>, <Topic: Topic 11>, <Topic: Topic 12>, <Topic: Topic 14>, <Topic: Topic 15>, <Topic: Topic 16>, <Topic: Topic 17>, <Topic: Topic 18>, <Topic: Topic 19>, <Topic: Topic 20>, <Topic: Topic 2>, <Topic: Topic 3>, <Topic: Topic 4>, <Topic: Topic 6>, <Topic: Topic 7>, <Topic: Topic 9>, <Topic: Topic 10>, <Topic: Topic 11>, '...(remaining elements truncated)...']>\n",
      "[481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510]\n",
      "Adding topicterms to db\n",
      "done in 1.024s.\n",
      "saving primary topic not working\n",
      "117\n",
      "RunStats object (117)\n",
      "done! total time: 24 minutes and 55 seconds\n",
      "a maximum of 1220.048 MB was used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, K, method='DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Blei DTM algorithm\n",
      "Extracting word features...\n",
      "done in 119.577s.\n",
      "Save terms to DB\n",
      "write input files for Blei algorithm\n",
      "Calling Blei algorithm\n",
      "Blei algorithm done\n",
      "upload dtm results to db\n",
      "writing topic terms\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "writing doctopics\n",
      "119\n",
      "RunStats object (119)\n",
      "done! total time: 268 minutes and 34 seconds\n",
      "a maximum of 945.744 MB was used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, 30, method='BT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Blei DTM algorithm\n",
      "Extracting word features...\n",
      "done in 124.474s.\n",
      "Save terms to DB\n",
      "write input files for Blei algorithm\n",
      "Calling Blei algorithm\n",
      "Blei algorithm done\n",
      "upload dtm results to db\n",
      "writing topic terms\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "13\n",
      "7\n",
      "15\n",
      "3\n",
      "5\n",
      "9\n",
      "11\n",
      "1\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "17\n",
      "19\n",
      "25\n",
      "21\n",
      "23\n",
      "27\n",
      "29\n",
      "32\n",
      "34\n",
      "31\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "33\n",
      "46\n",
      "39\n",
      "37\n",
      "41\n",
      "35\n",
      "43\n",
      "45\n",
      "48\n",
      "47\n",
      "49\n",
      "writing doctopics\n",
      "122\n",
      "RunStats object (122)\n",
      "done! total time: 410 minutes and 33 seconds\n",
      "a maximum of 778.852 MB was used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tm(ut_search_pdf.id, 50, method='BT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmv_yt",
   "language": "python",
   "name": "tmv_yt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
